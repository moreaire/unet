{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcda1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.io\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor, Lambda, RandomCrop\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.ndimage.measurements import center_of_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "859e4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR PREPROCESSING ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3db2f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_rand_seed(seed=10):\n",
    "    '''\n",
    "    Creates random seed for each library so that randomness is repeatable. Initialized first to set all randomness\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def save(sample, mask, name, i, sample_name, sample_address, orig_name, cropped):\n",
    "    \"\"\"\n",
    "    Saves file in sim_data folder with iterating number to correspond to number of samples desired as pytorch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    if cropped:\n",
    "        for j in range (len(sample)):\n",
    "            input_tensor = torch.tensor(sample[j])\n",
    "            mask_tensor = torch.tensor(mask[j])\n",
    "            \n",
    "            file_name = f\"/nsls2/users/maire1/unet/data/labeled_images/cropped_data/img{i}cropped{j}_pp.pt\"\n",
    "            torch.save({\"input\": input_tensor, \"target\": mask_tensor}, file_name)\n",
    "            sample_name.append(f\"img{i}cropped{j}_pp.pt\")\n",
    "            sample_address.append(file_name)\n",
    "\n",
    "    else:\n",
    "        input_tensor = torch.Tensor(sample)\n",
    "        mask_tensor = torch.Tensor(mask)\n",
    "        \n",
    "        file_name = f\"/nsls2/users/maire1/unet/data/labeled_images/real_data/img{i}_pp.pt\"\n",
    "        torch.save({\"input\": input_tensor, \"target\": mask_tensor}, file_name)\n",
    "        sample_name.append(f\"img{i}_pp.pt\")\n",
    "        sample_address.append(file_name)\n",
    "    orig_name.append(name)\n",
    "\n",
    "    return(sample_name, sample_address, orig_name)\n",
    "\n",
    "def save_total_data(name, address, orig_name, cropped):\n",
    "    \"\"\"\n",
    "    Saving titles and sample addresses into a separate csv file for use in the neural network.\n",
    "    \n",
    "    TODO: Save as a torch tensor in the future. \n",
    "    \"\"\"\n",
    "\n",
    "#     d = {'sample': name, 'address': address, 'original file name': orig_name[:len(address)]}\n",
    "#     df = pd.DataFrame(data=d)\n",
    "    print(len(name), len(address), len(orig_name))\n",
    "    if cropped:\n",
    "        d = {'sample': name, 'address': address}\n",
    "        filename = '/nsls2/users/maire1/unet/data/labeled_images/cropped_data/cropped_img_address_pp.csv'\n",
    "    else:\n",
    "        d = {'sample': name, 'address': address, 'original file name': orig_name[:len(address)]}\n",
    "        filename = '/nsls2/users/maire1/unet/data/labeled_images/real_data/img_address_pp.csv'\n",
    "    df = pd.DataFrame(data=d)\n",
    "    df.to_csv(filename, index = False)\n",
    "    print(\"All samples completed. Data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bc2449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(orig_img, target, sample_num):\n",
    "    set_rand_seed()\n",
    "    pt_img = torch.tensor(orig_img)\n",
    "    pt_target = torch.tensor(target)\n",
    "    cropper = T.RandomCrop(size=(256, 256))\n",
    "    crops = [cropper(pt_img) for j in range(sample_num)]\n",
    "    set_rand_seed()\n",
    "    mask_crops = [cropper(pt_target) for j in range(sample_num)]\n",
    "    #plot(pt_img, crops)\n",
    "    #plot(pt_target, mask_crops)\n",
    "    return crops, mask_crops\n",
    "\n",
    "def plot(orig_img, imgs, with_orig=True, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [orig_img] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(8)\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d99a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(x, n):\n",
    "    xr = np.zeros((x.shape[0]//n,x.shape[1]//n ))\n",
    "    for j in range(0, x.shape[0]-n, n):\n",
    "        for i in range(0, x.shape[1]-n, n):\n",
    "            xr[j//n, i//n] = np.nanmean(x[j:j+n, i:i+n])\n",
    "    return xr\n",
    "\n",
    "# I haven't checked it yet. But the idea should be to selec the nearest label\n",
    "# that is not a background\n",
    "def resize_target(x, n): \n",
    "    xr = np.zeros((x.shape[0]//n,x.shape[1]//n ))\n",
    "    for j in range(0, x.shape[0]-n, n):\n",
    "        for i in range(0, x.shape[1]-n, n):\n",
    "            xr[j//n, i//n] = np.nanmax(x[j:j+n, i:i+n])\n",
    "    return xr\n",
    "\n",
    "def transform(img):\n",
    "    # transformation of CHX data\n",
    "    img[img>2000] = 0\n",
    "    img[255:260, :] = 0\n",
    "    img[805:810, :] = 0\n",
    "    img[1357:1361, :] = 0\n",
    "    img[1908:1912, :] = 0\n",
    "    img[920:950, 1150:] = 0\n",
    "\n",
    "    x_c, y_c = center_of_mass(img)\n",
    "\n",
    "    # add a random dispacement if needed\n",
    "    # maybe, leave it for later for data augmentation\n",
    "    # x_c += np.random.randint(-100, 100)\n",
    "    # y_c += np.random.randint(-100, 100\n",
    "\n",
    "    size = 512\n",
    "    x_c = np.max(int(x_c)-size//2, 0)\n",
    "    y_c = np.max(int(y_c)-size//2, 0)\n",
    "    #print(x_c, y_c)\n",
    "    #plt.figure(dpi = 300)\n",
    "    cropped_x = img[x_c:x_c+size, y_c:y_c+size]\n",
    "    #plt.imshow(cropped_x , vmin = 0, vmax =5, origin = 'lower')\n",
    "    \n",
    "    y = resize(cropped_x, 2)\n",
    "    y_smooth = gaussian_filter(y, sigma=2)\n",
    "    y = gaussian_filter(y, sigma=0.3)\n",
    "    y = (y - y_smooth.min())/(y_smooth.max() - y_smooth.min())\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61e43c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-87d1697947fb>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(sample[j])\n",
      "<ipython-input-18-87d1697947fb>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_tensor = torch.tensor(mask[j])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19 38\n",
      "All samples completed. Data saved.\n",
      "190 190 38\n",
      "All samples completed. Data saved.\n"
     ]
    }
   ],
   "source": [
    "datafile = '/nsls2/users/maire1/unet/data/labeled_images/real_data/data_address.csv'\n",
    "file = pd.read_csv(datafile)\n",
    "partition = file['address']# IDs\n",
    "labels = file['sample']# Labels\n",
    "name = file['original file name']\n",
    "sample_num = 10\n",
    "\n",
    "sample_name = []\n",
    "cropped_sample_name = []\n",
    "sample_address = []\n",
    "cropped_sample_address = []\n",
    "orig_name = []\n",
    "\n",
    "size = (256,256)\n",
    "\n",
    "for i in range (len(partition)):\n",
    "    #img = torch.load(f'/nsls2/users/maire1/unet/data/unet/real_data/{label}')\n",
    "    img = np.load(f'/nsls2/users/maire1/unet/data/labeled_images/images_chx/{name[i]}.npy')\n",
    "    img_mask = skimage.io.imread(f'/nsls2/users/maire1/unet/data/labeled_images/labeled_images_chx/{name[i]}_labeled.tif')\n",
    "    \n",
    "    img = transform(img)\n",
    "    img_mask = transform(img_mask)\n",
    "    \n",
    "    #orig_img = img['input']\n",
    "    #target = img['target']\n",
    "    \n",
    "    sample_name, sample_address, orig_name = save(img, img_mask, name, i, sample_name, sample_address, orig_name, False)\n",
    "    crops, mask_crops = crop(img, img_mask, sample_num)\n",
    "    cropped_sample_name, cropped_sample_address, orig_name = save(crops, mask_crops, name, i, cropped_sample_name, cropped_sample_address, orig_name, True)\n",
    "\n",
    "    \n",
    "save_total_data(sample_name, sample_address, orig_name, False)\n",
    "save_total_data(cropped_sample_name, cropped_sample_address, orig_name, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7f7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fb620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
