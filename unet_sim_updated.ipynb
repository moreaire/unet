{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809d6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SETTING UP U-NET NEURAL NETWORK'''\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''\n",
    "    Block has three layers: two convolution operators (no padding)\n",
    "    and one with ReLU activation\n",
    "    '''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 5, padding='same')\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 5, padding='same')        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv2(self.relu(self.conv1(x)))\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    Encoder: Maxpooling (used for downsampling) performed between two Block operations\n",
    "    This class includes the block operations already\n",
    "    '''\n",
    "    def __init__(self, chs=(1,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "        self.pool       = nn.MaxPool2d(2)\n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return ftrs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    Decoder: Series of upconvolutions and decoders to expand matrix in order to determine location\n",
    "    '''\n",
    "    def __init__(self, chs=(1024, 512, 256, 128, 64)):\n",
    "        super().__init__()\n",
    "        self.chs         = chs\n",
    "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
    "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
    "        \n",
    "    def forward(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)-1):\n",
    "            x        = self.upconvs[i](x)\n",
    "            enc_ftrs = self.crop(encoder_features[i], x)\n",
    "            x        = torch.cat([x, enc_ftrs], dim=1)\n",
    "            x        = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    \n",
    "    def crop(self, enc_ftrs, x):\n",
    "        _, _, H, W = x.shape\n",
    "        enc_ftrs   = transforms.CenterCrop([H, W])(enc_ftrs)\n",
    "        return enc_ftrs\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    '''\n",
    "    Code to set up encoders and decoder layers\n",
    "    '''\n",
    "    def __init__(self, enc_chs=(1,2,4,8,16,32), dec_chs=(32, 16,8, 4, 2), num_class=3, retain_dim=True, out_sz=(1024,1024)):\n",
    "        super().__init__()\n",
    "        self.encoder     = Encoder(enc_chs)\n",
    "        self.decoder     = Decoder(dec_chs)\n",
    "        self.head        = nn.Conv2d(dec_chs[-1], num_class, 1)\n",
    "        #self.retain_dim  = retain_dim\n",
    "\n",
    "    def forward(self, x, out_sz=(256,256)):\n",
    "        enc_ftrs = self.encoder(x)\n",
    "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
    "        out      = self.head(out)\n",
    "        \n",
    "        #if self.retain_dim:\n",
    "            #out = nn.functional.interpolate(out, out_sz)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SETUP DATASETS'''\n",
    "\n",
    "def normalization(x):\n",
    "    '''\n",
    "    Used to normalize sample data so that it is between 0 and 1.\n",
    "    This is only used on the input image, not the mask\n",
    "    '''\n",
    "#     x_max = torch.max(x)\n",
    "#     x_min = torch.min(x)\n",
    "#     x_norm = (x-x_min)/(x_max-x_min)\n",
    "    \n",
    "    x_mean = torch.mean(x)\n",
    "    x_stdev = torch.std(x)\n",
    "    x_norm = (x-x_mean)/(x_stdev)\n",
    "    return x_norm\n",
    "\n",
    "def rand_input(x, **kwargs):\n",
    "    '''\n",
    "    This function randomizes the mask values and replaces the original values with random\n",
    "    numbers between 0 and 1. This function was created in order to bypass the thresholding\n",
    "    we experienced during initial tests. (The model categorized on intensity rather than shape)\n",
    "    The mask values on the input are always 0 for background, 1 for streaks, 2 for beam stop\n",
    "    '''\n",
    "    x = x.float().to(device)\n",
    "    val = torch.rand(3).to(device) #Generate three random numbers and assign to each value \n",
    "    x = torch.where(x==0,val[0],x)\n",
    "    x = torch.where(x==1, val[1],x)\n",
    "    x = torch.where(x==2, val[2],x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "#'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        \n",
    "        # In order to handle different indexing for validation and training data\n",
    "        while True:\n",
    "            try:\n",
    "                ID = self.list_IDs[index]\n",
    "                break\n",
    "            except:\n",
    "                index += len(self.list_IDs)\n",
    "                \n",
    "        # Load data and get label\n",
    "        X = torch.load(ID)\n",
    "        plt.imshow(X[\"target\"])\n",
    "        plt.title(\"Raw image\")\n",
    "        plt.show()\n",
    "#         plt.hist(X['target'][:,0].cpu().detach().numpy().flatten())\n",
    "#         plt.show()\n",
    "\n",
    "        #Randomize\n",
    "        x_rand = rand_input(X['target']).cpu()\n",
    "#         plt.imshow(x_rand)\n",
    "#         plt.title(\"Image with values randomized\")\n",
    "#         plt.show()\n",
    "        #x_rand += 0.1*torch.rand(x_rand.shape)\n",
    "\n",
    "        X['input'] = normalization(x_rand)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2409cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''FUNCTIONS'''\n",
    "\n",
    "def cuda_setup():\n",
    "    # CUDA for PyTorch\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"Using {} device\".format(device))\n",
    "    \n",
    "    return(device)\n",
    "\n",
    "def set_rand_seed(seed):\n",
    "    '''\n",
    "    Creates random seed for each library so that randomness is repeatable. \n",
    "    Initialized first to set all randomness\n",
    "    '''\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "def save_params(output_array, orig_array, params, desc, loss, model, optimizer, i):\n",
    "    '''\n",
    "    Saves what I have changed in each iteration\n",
    "    \n",
    "    Inputs:\n",
    "        Long string of output graphs\n",
    "        List of params\n",
    "        Comments of what was changed. \n",
    "    Outputs: \n",
    "        Pytorch file which lists all of these in a dictionary\n",
    "        \n",
    "    TODO: This function is no where near complete. Will need to look at this in-depth\n",
    "    '''\n",
    "    \n",
    "    output_tensor = torch.Tensor(output_array)\n",
    "    orig_tensor = torch.Tensor(orig_array)\n",
    "    \n",
    "    torch.save({\n",
    "        \"output\": output_tensor, \n",
    "        \"original\": orig_tensor, \n",
    "        \"params\":params, \n",
    "        \"description\": desc, \n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss}, \n",
    "        f\"nsls2/users/maire1/unet/params_list{i}.pt\")\n",
    "    i += 1\n",
    "    return i\n",
    "\n",
    "def calculate_weights(target):\n",
    "    '''\n",
    "    Calculates the weight which should be assigned based off of the target.\n",
    "    This is done to give more importance to values which are not represented equally \n",
    "    amount-wise. \n",
    "    \n",
    "    Inputs: Target array\n",
    "    Outputs: Array of weights for each value\n",
    "    '''\n",
    "    \n",
    "    #Find the amount of pixels which belong to each category \n",
    "    total = target.numel()\n",
    "    stop = target.eq(2).sum().item()/2\n",
    "    streaks = target.eq(1).sum().item()\n",
    "    bkgnd = total - streaks - stop\n",
    "    \n",
    "    #Need to have a lot of edge cases in case if there are no streaks, beamstops, etc. in the image\n",
    "    if streaks == 0 and stop == 0:\n",
    "        weights = [1, 1, 1]\n",
    "    elif streaks == 0:\n",
    "        weights = [1, 1, bkgnd/stop]\n",
    "    elif stop == 0:\n",
    "        weights = [1, bkgnd/streaks, 1]\n",
    "    else:\n",
    "        weights = [1, bkgnd/streaks, bkgnd/stop]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ad2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, device, training_graphs, orig_images):\n",
    "    '''\n",
    "    This function can likely be split into smaller functions. The training function will\n",
    "    analyze the training data and output the loss. \n",
    "    \n",
    "    Note: There are a lot of things commented out. Some lines which are commented out\n",
    "    were used for simulation data, and they do not work on real data. Other lines \n",
    "    were commented out based on whether we are using target data as the input or not. \n",
    "    Each line will have a marker explaining what it is for (Toy Data or Target or Real)'''\n",
    "    \n",
    "    size = len(dataloader)\n",
    "    model.train()\n",
    "    loss_tot = np.zeros(size)\n",
    "    \n",
    "    for batch_num, local_batch in enumerate (dataloader):\n",
    "\n",
    "        # Transfer to GPU\n",
    "        for key, value in local_batch.items():\n",
    "#             local_batch[key] = value.to(device) #Toy data\n",
    "            local_batch[key] = value.float().to(device) #REAL DATA CHANGE\n",
    "#        in_batch = local_batch['input'].unsqueeze(1) #Using image as input\n",
    "        in_batch = local_batch['target'].unsqueeze(1) #Using target as input\n",
    "        \n",
    "        #Run input through the model\n",
    "        out  = model(in_batch)\n",
    "        \n",
    "        target = local_batch['target']\n",
    "        \n",
    "        #WEIGHTS\n",
    "        weight = calculate_weights(target)\n",
    "        class_weight = torch.FloatTensor(weight).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss(class_weight)\n",
    "        loss = loss_fn(out, target.long())\n",
    "\n",
    "#         #GRAPHING PT 1\n",
    "          #There are more opportunities to see the output beyond this (see end of code)\n",
    "          #This graphing outputs thousands of images. \n",
    "#         nn_image = out.argmax(1)\n",
    "#         nn_image = nn_image[0,:,:].cpu().numpy()\n",
    "#         training_graphs.append(nn_image)\n",
    "        \n",
    "#         y_graph = in_batch[0,0,:,:].cpu().numpy()\n",
    "#         orig_images.append(y_graph)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss = loss.cpu().detach()\n",
    "        \n",
    "        loss, current = loss.item(), batch_num #* len(out)\n",
    "        # print(f\"loss: {loss:>7f}  [{(current+1):>5d}/{size:>5d}]\")\n",
    "        loss_tot[batch_num] = loss\n",
    "        \n",
    "        if torch.cuda.torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    mean = np.mean(loss_tot)\n",
    "    print(\"Train Mean Loss: \", mean)\n",
    "    \n",
    "\n",
    "    #GRAPHING CTD.\n",
    "#     for i in range (len(training_graphs)):\n",
    "#         plt.imshow(training_graphs[i])\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.imshow(orig_images[i])\n",
    "#         plt.show()\n",
    "\n",
    "    return training_graphs, orig_images, loss, optimizer\n",
    "    \n",
    "                \n",
    "def validation(dataloader, model, device):\n",
    "    '''\n",
    "    This function is largely similar to the training function.\n",
    "    This will display the loss and accuracy\n",
    "    \n",
    "    TODO: Fix accuracy output. '''\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0 #This adds throughout the process\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, local_batch in enumerate (dataloader):\n",
    "            # Transfer to GPU\n",
    "            for key, value in local_batch.items():\n",
    "#                 local_batch[key] = value.to(device) #Toy data\n",
    "                local_batch[key] = value.float().to(device) #FOR REAL DATA\n",
    "                \n",
    "            #pred = model(local_batch['input'].unsqueeze(1)) #Image as input\n",
    "            y = local_batch['target']\n",
    "            pred = model(y.unsqueeze(1)) #Target as input\n",
    "            \n",
    "            #WEIGHTS\n",
    "            weight = calculate_weights(y)\n",
    "            class_weight = torch.FloatTensor(weight).to(device)\n",
    "            loss_fn = nn.CrossEntropyLoss(class_weight) \n",
    "            \n",
    "            test_loss += loss_fn(pred, y.long())#.detach()\n",
    "            \n",
    "            correct += (pred.argmax(axis=1) == y).type(torch.float).sum()\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum()#.detach()\n",
    "            tot_pts = torch.numel(y)\n",
    "            \n",
    "        #Calculating test loss by dividing total loss over batch size\n",
    "        size = batch_num + 1\n",
    "        test_loss /= size\n",
    "        #print (\"Correct:\", correct.shape(), \"\\nTotal Size: \", size*tot_pts)\n",
    "        correct /= (size*tot_pts)\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "        \n",
    "        if torch.cuda.torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f352d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMS\n",
    "params = {'batch_size': 4, #Number of samples in each batch\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0} #Number of process to generate batches in //\n",
    "max_epochs = 33 \n",
    "learning_rate = 1e-3\n",
    "training_num = 160 #This is an arbitrary number\n",
    "num = 0 #FOR RANDOM SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_rand_seed(num)\n",
    "\n",
    "#Init\n",
    "output_array = []\n",
    "orig_array = []\n",
    "#desc = \"First saving run. Only trained on the mask input\" #For future model saving\n",
    "\n",
    "#Training\n",
    "#datafile =  \"/nsls2/users/maire1/sim_data/sim_address.csv\" #For simulation data\n",
    "datafile = \"/nsls2/users/maire1/unet/data/cropped_data/data_address.csv\" \n",
    "  \n",
    "# Determine and setup device\n",
    "device = cuda_setup()\n",
    "\n",
    "# Datasets\n",
    "# Separating datasets into training and validation. \n",
    "file = pd.read_csv(datafile)\n",
    "partition = file['address']# IDs\n",
    "training_partition = partition[:training_num]\n",
    "validation_partition = partition[training_num:]\n",
    "\n",
    "labels = file['sample']# Labels\n",
    "training_labels = labels[:training_num]\n",
    "validation_labels = labels[training_num:]\n",
    "\n",
    "model = UNet().to(device) #comment this out when you start training\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(training_partition, training_labels)\n",
    "training_generator = DataLoader(training_set, **params, pin_memory=True)\n",
    "\n",
    "validation_set = Dataset(validation_partition, validation_labels)\n",
    "validation_generator = DataLoader(validation_set, **params, pin_memory=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    output_array, orig_array, loss, optimizer = train(training_generator, model, optimizer, device, training_graphs=output_array, orig_images=orig_array)\n",
    "    validation(validation_generator, model, device)\n",
    "    \n",
    "#i = save_params(output_array, orig_array, params, desc, loss, model, optimizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b259909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR GRAPHING A FEW OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_batch = next(iter(training_generator))\n",
    "x = local_batch['input'].unsqueeze(1).to(device)\n",
    "# x_r = rand_input(x)\n",
    "# x_norm = normalization(x_r)\n",
    "x_hat = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45784558",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, dpi = 200)\n",
    "\n",
    "k =2\n",
    "\n",
    "ax[0].imshow(x[k, 0, :, :].cpu().detach().numpy())#, vmin = -1, vmax = 1)\n",
    "ax[1].imshow(x_hat[k, :, :, :].cpu().detach().numpy().argmax(0))#, vmin = 0, vmax = 2)\n",
    "#ax[1].imshow(x_hat[k, 1, :, :].cpu().detach().numpy(), vmin = 0, vmax = 2) \n",
    "ax[2].imshow(local_batch['target'][k])\n",
    "for j in range(3):\n",
    "    ax[j].axis('off')\n",
    "    \n",
    "ax[0].set_title('input')\n",
    "ax[1].set_title('model output')\n",
    "ax[2].set_title('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x[2,0,:,:].cpu().detach().numpy().flatten())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
