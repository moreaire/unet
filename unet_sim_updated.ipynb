{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809d6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bba03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SETTING UP U-NET NEURAL NETWORK'''\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''\n",
    "    Block has three layers: two convolution operators (no padding)\n",
    "    and one with ReLU activation\n",
    "    '''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 5, padding='same')\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 5, padding='same')        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv2(self.relu(self.conv1(x)))\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    Encoder: Maxpooling (used for downsampling) performed between two Block operations\n",
    "    This class includes the block operations already\n",
    "    '''\n",
    "    def __init__(self, chs=(1,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "        self.pool       = nn.MaxPool2d(2)\n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return ftrs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    Decoder: Series of upconvolutions and decoders to expand matrix in order to determine location\n",
    "    '''\n",
    "    def __init__(self, chs=(1024, 512, 256, 128, 64)):\n",
    "        super().__init__()\n",
    "        self.chs         = chs\n",
    "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
    "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
    "        \n",
    "    def forward(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)-1):\n",
    "            x        = self.upconvs[i](x)\n",
    "            enc_ftrs = self.crop(encoder_features[i], x)\n",
    "            x        = torch.cat([x, enc_ftrs], dim=1)\n",
    "            x        = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    \n",
    "    def crop(self, enc_ftrs, x):\n",
    "        _, _, H, W = x.shape\n",
    "        enc_ftrs   = transforms.CenterCrop([H, W])(enc_ftrs)\n",
    "        return enc_ftrs\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    '''\n",
    "    Code to set up encoders and decoder layers\n",
    "    '''\n",
    "    def __init__(self, enc_chs=(1,2,4,8,16,32), dec_chs=(32, 16,8, 4, 2), num_class=3, retain_dim=True, out_sz=(1024,1024)):\n",
    "        super().__init__()\n",
    "        self.encoder     = Encoder(enc_chs)\n",
    "        self.decoder     = Decoder(dec_chs)\n",
    "        self.head        = nn.Conv2d(dec_chs[-1], num_class, 1)\n",
    "        #self.retain_dim  = retain_dim\n",
    "\n",
    "    def forward(self, x, out_sz=(256,256)):\n",
    "        enc_ftrs = self.encoder(x)\n",
    "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
    "        out      = self.head(out)\n",
    "        \n",
    "        #if self.retain_dim:\n",
    "            #out = nn.functional.interpolate(out, out_sz)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd9c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SETUP DATASETS'''\n",
    "\n",
    "def normalization(x):\n",
    "    '''\n",
    "    Used to normalize sample data so that it is between 0 and 1\n",
    "    '''\n",
    "#     x_max = torch.max(x)\n",
    "#     x_min = torch.min(x)\n",
    "#     x_norm = (x-x_min)/(x_max-x_min)\n",
    "    \n",
    "    x_mean = torch.mean(x)\n",
    "    x_stdev = torch.std(x)\n",
    "    x_norm = (x-x_mean)/(x_stdev)\n",
    "    return x_norm\n",
    "\n",
    "def rand_input(x, **kwargs):\n",
    "    x = x.float().to(device)\n",
    "    val = torch.rand(3).to(device)\n",
    "    x = torch.where(x==0,val[0],x)\n",
    "    x = torch.where(x==1, val[1],x)\n",
    "    x = torch.where(x==2, val[2],x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "#'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # In order to handle different indexing for validation and training data\n",
    "        while True:\n",
    "            try:\n",
    "                ID = self.list_IDs[index]\n",
    "                break\n",
    "            except:\n",
    "                index += len(self.list_IDs)\n",
    "        # Load data and get label\n",
    "        X = torch.load(ID)\n",
    "        x_rand = rand_input(X['target']).cpu()\n",
    "        #x_rand += 0.1*torch.rand(x_rand.shape)\n",
    "\n",
    "        X['input'] = normalization(x_rand)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2409cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''FUNCTIONS'''\n",
    "\n",
    "def cuda_setup():\n",
    "    # CUDA for PyTorch\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"Using {} device\".format(device))\n",
    "    \n",
    "    return(device)\n",
    "\n",
    "def set_rand_seed(seed):\n",
    "    '''\n",
    "    Creates random seed for each library so that randomness is repeatable. Initialized first to set all randomness\n",
    "    '''\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "\n",
    "# def optimization_plots(x, y):\n",
    "#     # x: epoch number, y: training\n",
    "#     plt.plot(x, y)\n",
    "#     plt.xlabel(\"Epoch Number\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "#     plt.title(\"Learning Plot\")\n",
    "#     plt.show()\n",
    "\n",
    "def save_params(output_array, orig_array, params, desc, loss, model, optimizer, i):\n",
    "    '''\n",
    "    Saves what I have changed in each iteration\n",
    "    \n",
    "    Inputs:\n",
    "        Long string of output graphs\n",
    "        List of params\n",
    "        Comments of what was changed. \n",
    "    Outputs: \n",
    "        Pytorch file which lists all of these in a dictionary\n",
    "    '''\n",
    "    \n",
    "    output_tensor = torch.Tensor(output_array)\n",
    "    orig_tensor = torch.Tensor(orig_array)\n",
    "    \n",
    "    torch.save({\n",
    "        \"output\": output_tensor, \n",
    "        \"original\": orig_tensor, \n",
    "        \"params\":params, \n",
    "        \"description\": desc, \n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss}, \n",
    "        f\"nsls2/users/maire1/unet/params_list{i}.pt\")\n",
    "    i += 1\n",
    "    return i\n",
    "\n",
    "def calculate_weights(target):\n",
    "    #t = normalization(target)\n",
    "    total = target.numel()\n",
    "    stop = target.eq(2).sum().item()/2\n",
    "    streaks = target.eq(1).sum().item()\n",
    "    bkgnd = total - streaks - stop\n",
    "    if streaks == 0 and stop == 0:\n",
    "        weights = [1, 1, 1]\n",
    "    elif streaks == 0:\n",
    "        weights = [1, 1, bkgnd/stop]\n",
    "    elif stop == 0:\n",
    "        weights = [1, bkgnd/streaks, 1]\n",
    "    else:\n",
    "        weights = [1, bkgnd/streaks, bkgnd/stop]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446ad2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, device, training_graphs, orig_images):\n",
    "    size = len(dataloader)\n",
    "    model.train()\n",
    "    loss_tot = np.zeros(size)\n",
    "    \n",
    "    for batch_num, local_batch in enumerate (dataloader):\n",
    "\n",
    "        # Transfer to GPU\n",
    "        for key, value in local_batch.items():\n",
    "#             local_batch[key] = value.to(device)\n",
    "            local_batch[key] = value.float().to(device) #REAL DATA CHANGE\n",
    "#        in_batch = local_batch['input'].unsqueeze(1)\n",
    "        in_batch = local_batch['target'].unsqueeze(1)\n",
    "        \n",
    "#         in_batch_norm = normalization(in_batch)\n",
    "#         in_batch_rand = rand_input(in_batch_norm)\n",
    "        out  = model(in_batch)\n",
    "        #out = model(in_batch)\n",
    "        target = local_batch['target']\n",
    "        \n",
    "        #WEIGHTS\n",
    "        weight = calculate_weights(target)\n",
    "        class_weight = torch.FloatTensor(weight).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss(class_weight)\n",
    "        loss = loss_fn(out, target.long())\n",
    "\n",
    "#         #GRAPHING\n",
    "#         nn_image = out.argmax(1)\n",
    "#         nn_image = nn_image[0,:,:].cpu().numpy()\n",
    "#         training_graphs.append(nn_image)\n",
    "        \n",
    "#         y_graph = in_batch[0,0,:,:].cpu().numpy()\n",
    "#         orig_images.append(y_graph)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss = loss.cpu().detach()\n",
    "        \n",
    "        loss, current = loss.item(), batch_num #* len(out)\n",
    "        # print(f\"loss: {loss:>7f}  [{(current+1):>5d}/{size:>5d}]\")\n",
    "        loss_tot[batch_num] = loss\n",
    "        \n",
    "        if torch.cuda.torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    mean = np.mean(loss_tot)\n",
    "    print(\"Train Mean Loss: \", mean)\n",
    "    \n",
    "\n",
    "    #GRAPHING CTD.\n",
    "    for i in range (len(training_graphs)):\n",
    "        plt.imshow(training_graphs[i])\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(orig_images[i])\n",
    "        plt.show()\n",
    "\n",
    "    return training_graphs, orig_images, loss, optimizer\n",
    "    \n",
    "                \n",
    "def validation(dataloader, model, device):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, local_batch in enumerate (dataloader):\n",
    "            # Transfer to GPU\n",
    "            \n",
    "            for key, value in local_batch.items():\n",
    "#                 local_batch[key] = value.to(device) \n",
    "                local_batch[key] = value.float().to(device) #FOR REAL DATA\n",
    "                \n",
    "            #pred = model(local_batch['input'].unsqueeze(1))\n",
    "            y = local_batch['target']\n",
    "            #pred = model(y.unsqueeze(1))\n",
    "            \n",
    "#            in_val = local_batch['input'].unsqueeze(1)\n",
    "            in_val = local_batch['target'].unsqueeze(1)\n",
    "#             in_val_norm = normalization(in_val)\n",
    "#             in_val_rand = rand_input(in_val_norm)\n",
    "            pred = model(in_val)\n",
    "            \n",
    "            \n",
    "            #WEIGHTS\n",
    "            weight = calculate_weights(y)\n",
    "            class_weight = torch.FloatTensor(weight).to(device)\n",
    "            loss_fn = nn.CrossEntropyLoss(class_weight) \n",
    "            \n",
    "            test_loss += loss_fn(pred, y.long())#.detach()\n",
    "            \n",
    "            correct += (pred.argmax(axis=1) == y).type(torch.float).sum()\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum()#.detach()\n",
    "            tot_pts = torch.numel(y)\n",
    "            \n",
    "\n",
    "        size = batch_num + 1\n",
    "        test_loss /= size\n",
    "        #print (\"Correct:\", correct.shape(), \"\\nTotal Size: \", size*tot_pts)\n",
    "        correct /= (size*tot_pts)\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "        \n",
    "        if torch.cuda.torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed45af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603b4268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n",
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nsls2/users/maire1/SULI/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Loss:  1.011241641640663\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 1.008134\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train Mean Loss:  1.0051156669855117\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 1.002091\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9991542279720307\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.996199\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9933387503027916\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.990479\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9876753360033035\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.984883\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9821659922599792\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.979469\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9767781749367714\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.974142\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9715213492512703\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.968936\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9663766339421272\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.963866\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9613603442907334\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.958946\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9564652621746064\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.954095\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9516638711094856\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.949353\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9469670504331589\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.944701\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9423828408122062\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.940179\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9378692239522934\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.935678\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9334484606981277\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.931343\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9291045024991036\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.927016\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9248049393296242\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.922843\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9206191450357437\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.918620\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9164725065231323\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.914553\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9123825609683991\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.910470\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9083689138293266\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.906538\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9043798968195915\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.902561\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.9004403457045556\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.898562\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.8965081483125686\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.894671\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.8926073595881462\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.890812\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.888731698691845\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.886946\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.884875038266182\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.883126\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.8810167849063874\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.879287\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.8771292299032212\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.875340\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.8732644453644752\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.871503\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.8693052262067795\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.867541\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Train Mean Loss:  0.8653481513261795\n",
      "Test Error: \n",
      " Accuracy: 158.0%, Avg loss: 0.863520\n"
     ]
    }
   ],
   "source": [
    "params = {'batch_size': 4, #Number of samples in each batch\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0} #Number of process to generate batches in //\n",
    "max_epochs = 33 \n",
    "learning_rate = 1e-3\n",
    "num = 0 #FOR RANDOM SEED\n",
    "\n",
    "set_rand_seed(num)\n",
    "\n",
    "#Init\n",
    "output_array = []\n",
    "orig_array = []\n",
    "desc = \"First saving run. Only trained on the mask input\"\n",
    "\n",
    "#Training\n",
    "#datafile = \"data/sim_address.csv\"\n",
    "#datafile =  \"/nsls2/users/maire1/sim_data/sim_address.csv\"\n",
    "datafile = \"/nsls2/users/maire1/unet/data/unet/cropped_data/cropped_img_address_pp.csv\"\n",
    "\n",
    "#def main(datafile, params, max_epochs):\n",
    "    \n",
    "# Determine and setup device\n",
    "device = cuda_setup()\n",
    "\n",
    "# Datasets\n",
    "file = pd.read_csv(datafile)\n",
    "partition = file['address']# IDs\n",
    "training_partition = partition[:160]\n",
    "validation_partition = partition[160:]\n",
    "\n",
    "labels = file['sample']# Labels\n",
    "training_labels = labels[:160]\n",
    "validation_labels = labels[160:]\n",
    "\n",
    "model = UNet().to(device) #comment this out when you start training\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(training_partition, training_labels)\n",
    "training_generator = DataLoader(training_set, **params, pin_memory=True)\n",
    "\n",
    "validation_set = Dataset(validation_partition, validation_labels)\n",
    "\n",
    "validation_generator = DataLoader(validation_set, **params, pin_memory=True)\n",
    "# images, masks = next(iter(training_generator))['input'], next(iter(training_generator))['target']\n",
    "\n",
    "\n",
    "# weight = calculate_weights()\n",
    "# class_weight = torch.FloatTensor(weight).to(device)\n",
    "# loss_fn = nn.CrossEntropyLoss(class_weight)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    output_array, orig_array, loss, optimizer = train(training_generator, model, optimizer, device, training_graphs=output_array, orig_images=orig_array)\n",
    "    validation(validation_generator, model, device)\n",
    "    \n",
    "#i = save_params(output_array, orig_array, params, desc, loss, model, optimizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "257f0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_batch = next(iter(training_generator))\n",
    "x = local_batch['input'].unsqueeze(1).to(device)\n",
    "# x_r = rand_input(x)\n",
    "# x_norm = normalization(x_r)\n",
    "\n",
    "x_hat = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45784558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'target')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3, dpi = 200)\n",
    "\n",
    "k =2\n",
    "\n",
    "ax[0].imshow(x[k, 0, :, :].cpu().detach().numpy())#, vmin = -1, vmax = 1)\n",
    "ax[1].imshow(x_hat[k, :, :, :].cpu().detach().numpy().argmax(0))#, vmin = 0, vmax = 2)\n",
    "#ax[1].imshow(x_hat[k, 1, :, :].cpu().detach().numpy(), vmin = 0, vmax = 2) \n",
    "ax[2].imshow(local_batch['target'][k])\n",
    "for j in range(3):\n",
    "    ax[j].axis('off')\n",
    "    \n",
    "ax[0].set_title('input')\n",
    "ax[1].set_title('model output')\n",
    "ax[2].set_title('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ddaa428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.0220e+03, 4.0000e+01, 4.8000e+01, 2.6000e+01, 2.0000e+02,\n",
       "        5.6013e+04, 0.0000e+00, 6.0000e+00, 0.0000e+00, 7.1810e+03]),\n",
       " array([-3.395116  , -2.7912607 , -2.187405  , -1.5835497 , -0.97969425,\n",
       "        -0.37583876,  0.2280167 ,  0.83187217,  1.4357276 ,  2.0395832 ,\n",
       "         2.6434386 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x[2,0,:,:].cpu().detach().numpy().flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83701fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNNING CELL\n",
    "#------------------------------------------------\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 2, #Number of samples in each batch\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0} #Number of process to generate batches in //\n",
    "max_epochs = 4\n",
    "\n",
    "#Training\n",
    "datafile = \"/nsls2/users/maire1/sim_data/sim_address.csv\"\n",
    "\n",
    "main(datafile, params, max_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
